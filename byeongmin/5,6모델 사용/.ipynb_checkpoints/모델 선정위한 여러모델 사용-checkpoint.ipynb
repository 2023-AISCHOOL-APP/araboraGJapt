{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1c16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "767a613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../2~3.데이터 수집 및 전처리/머신러닝 전처리 데이터.CSV',encoding='EUC-KR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bcba66e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시군구</th>\n",
       "      <th>단지명</th>\n",
       "      <th>전용면적(㎡)</th>\n",
       "      <th>계약년월</th>\n",
       "      <th>계약일</th>\n",
       "      <th>계약날짜</th>\n",
       "      <th>층</th>\n",
       "      <th>건축나이</th>\n",
       "      <th>거래건수</th>\n",
       "      <th>기준금리</th>\n",
       "      <th>법정동코드</th>\n",
       "      <th>지하철역수</th>\n",
       "      <th>거래금액(만원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>광주광역시 광산구 도산동</td>\n",
       "      <td>대덕1</td>\n",
       "      <td>59.3100</td>\n",
       "      <td>202303</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-03-18</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2920010200</td>\n",
       "      <td>1</td>\n",
       "      <td>9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>광주광역시 광산구 도산동</td>\n",
       "      <td>대주피오레1차</td>\n",
       "      <td>84.9800</td>\n",
       "      <td>202302</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-02-07</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2920010200</td>\n",
       "      <td>1</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>광주광역시 광산구 도산동</td>\n",
       "      <td>대주피오레1차</td>\n",
       "      <td>84.9800</td>\n",
       "      <td>202305</td>\n",
       "      <td>31</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2920010200</td>\n",
       "      <td>1</td>\n",
       "      <td>22350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>광주광역시 광산구 도산동</td>\n",
       "      <td>대주피오레2차</td>\n",
       "      <td>84.7575</td>\n",
       "      <td>202305</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2920010200</td>\n",
       "      <td>1</td>\n",
       "      <td>22400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주광역시 광산구 도산동</td>\n",
       "      <td>대주피오레2차</td>\n",
       "      <td>84.7575</td>\n",
       "      <td>202305</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2920010200</td>\n",
       "      <td>1</td>\n",
       "      <td>22000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425074</th>\n",
       "      <td>광주광역시 서구 화정동</td>\n",
       "      <td>화정우미</td>\n",
       "      <td>115.1850</td>\n",
       "      <td>200611</td>\n",
       "      <td>10</td>\n",
       "      <td>2006-11-10</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>131</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2914011900</td>\n",
       "      <td>1</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425075</th>\n",
       "      <td>광주광역시 서구 화정동</td>\n",
       "      <td>화정우미</td>\n",
       "      <td>84.8300</td>\n",
       "      <td>200611</td>\n",
       "      <td>27</td>\n",
       "      <td>2006-11-27</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>131</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2914011900</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425076</th>\n",
       "      <td>광주광역시 서구 화정동</td>\n",
       "      <td>화정우미</td>\n",
       "      <td>59.8300</td>\n",
       "      <td>200611</td>\n",
       "      <td>30</td>\n",
       "      <td>2006-11-30</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>131</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2914011900</td>\n",
       "      <td>1</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425077</th>\n",
       "      <td>광주광역시 서구 화정동</td>\n",
       "      <td>화정우미</td>\n",
       "      <td>84.8400</td>\n",
       "      <td>200612</td>\n",
       "      <td>6</td>\n",
       "      <td>2006-12-06</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>124</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2914011900</td>\n",
       "      <td>1</td>\n",
       "      <td>12170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425078</th>\n",
       "      <td>광주광역시 서구 화정동</td>\n",
       "      <td>화정우미</td>\n",
       "      <td>115.1850</td>\n",
       "      <td>200612</td>\n",
       "      <td>12</td>\n",
       "      <td>2006-12-12</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>124</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2914011900</td>\n",
       "      <td>1</td>\n",
       "      <td>17500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425079 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  시군구      단지명   전용면적(㎡)    계약년월  계약일        계약날짜   층  건축나이  \\\n",
       "0       광주광역시 광산구 도산동      대덕1   59.3100  202303   18  2023-03-18   4    33   \n",
       "1       광주광역시 광산구 도산동  대주피오레1차   84.9800  202302    7  2023-02-07   2    23   \n",
       "2       광주광역시 광산구 도산동  대주피오레1차   84.9800  202305   31  2023-05-31   5    23   \n",
       "3       광주광역시 광산구 도산동  대주피오레2차   84.7575  202305    9  2023-05-09   5    22   \n",
       "4       광주광역시 광산구 도산동  대주피오레2차   84.7575  202305   13  2023-05-13  13    22   \n",
       "...               ...      ...       ...     ...  ...         ...  ..   ...   \n",
       "425074   광주광역시 서구 화정동     화정우미  115.1850  200611   10  2006-11-10  17    10   \n",
       "425075   광주광역시 서구 화정동     화정우미   84.8300  200611   27  2006-11-27   6    10   \n",
       "425076   광주광역시 서구 화정동     화정우미   59.8300  200611   30  2006-11-30   2    10   \n",
       "425077   광주광역시 서구 화정동     화정우미   84.8400  200612    6  2006-12-06  16    10   \n",
       "425078   광주광역시 서구 화정동     화정우미  115.1850  200612   12  2006-12-12  14    10   \n",
       "\n",
       "        거래건수  기준금리       법정동코드  지하철역수  거래금액(만원)  \n",
       "0         20   3.5  2920010200      1      9800  \n",
       "1         14   3.5  2920010200      1     21000  \n",
       "2         16   3.5  2920010200      1     22350  \n",
       "3         16   3.5  2920010200      1     22400  \n",
       "4         16   3.5  2920010200      1     22000  \n",
       "...      ...   ...         ...    ...       ...  \n",
       "425074   131   4.5  2914011900      1     19000  \n",
       "425075   131   4.5  2914011900      1     12000  \n",
       "425076   131   4.5  2914011900      1      7700  \n",
       "425077   124   4.5  2914011900      1     12170  \n",
       "425078   124   4.5  2914011900      1     17500  \n",
       "\n",
       "[425079 rows x 13 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961f9ac4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\gjaischool1\\anaconda3\\envs\\machine\\lib\\site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\gjaischool1\\anaconda3\\envs\\machine\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\gjaischool1\\anaconda3\\envs\\machine\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40000a3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.0.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "                                              0.0/1.3 MB ? eta -:--:--\n",
      "     ----------                               0.3/1.3 MB 7.0 MB/s eta 0:00:01\n",
      "     -----------------------------            1.0/1.3 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.3/1.3 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.3/1.3 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\gjaischool1\\anaconda3\\envs\\machine\\lib\\site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\gjaischool1\\anaconda3\\envs\\machine\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd78ecf1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "                                              0.0/77.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.1/77.1 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\gjaischool1\\anaconda3\\envs\\machine\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.65.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e82f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2e5733e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시군구</th>\n",
       "      <th>단지명</th>\n",
       "      <th>전용면적(㎡)</th>\n",
       "      <th>계약년월</th>\n",
       "      <th>계약일</th>\n",
       "      <th>계약날짜</th>\n",
       "      <th>층</th>\n",
       "      <th>건축나이</th>\n",
       "      <th>거래건수</th>\n",
       "      <th>기준금리</th>\n",
       "      <th>법정동코드</th>\n",
       "      <th>지하철역수</th>\n",
       "      <th>거래금액(만원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>광주광역시 광산구 도산동</td>\n",
       "      <td>대덕1</td>\n",
       "      <td>59.31</td>\n",
       "      <td>202303</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-03-18</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2920010200</td>\n",
       "      <td>1</td>\n",
       "      <td>9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>광주광역시 광산구 도산동</td>\n",
       "      <td>대주피오레1차</td>\n",
       "      <td>84.98</td>\n",
       "      <td>202302</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-02-07</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2920010200</td>\n",
       "      <td>1</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             시군구      단지명  전용면적(㎡)    계약년월  계약일        계약날짜  층  건축나이  거래건수  \\\n",
       "0  광주광역시 광산구 도산동      대덕1    59.31  202303   18  2023-03-18  4    33    20   \n",
       "1  광주광역시 광산구 도산동  대주피오레1차    84.98  202302    7  2023-02-07  2    23    14   \n",
       "\n",
       "   기준금리       법정동코드  지하철역수  거래금액(만원)  \n",
       "0   3.5  2920010200      1      9800  \n",
       "1   3.5  2920010200      1     21000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e5026465",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['계약연도'] = data['계약년월'] // 100\n",
    "data['계약월'] = data['계약년월'] % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a893b3b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         광주광역시 광산구 도산동\n",
       "1         광주광역시 광산구 도산동\n",
       "2         광주광역시 광산구 도산동\n",
       "3         광주광역시 광산구 도산동\n",
       "4         광주광역시 광산구 도산동\n",
       "              ...      \n",
       "425074     광주광역시 서구 화정동\n",
       "425075     광주광역시 서구 화정동\n",
       "425076     광주광역시 서구 화정동\n",
       "425077     광주광역시 서구 화정동\n",
       "425078     광주광역시 서구 화정동\n",
       "Name: 시군구, Length: 425079, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['시군구']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1a7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['전용면적(㎡)', '계약년도','계약월','층', '건축나이','거래건수','기준금리','법정동코드','지하철역수']]\n",
    "y = data['거래금액(만원)']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f266118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dacon 하이퍼파라미터튜닝 모델. 연습용\n",
    "lrmodel = LinearRegression(n_jobs=-1)\n",
    "ridge = Ridge(alpha=0.8, random_state=1)\n",
    "lasso = Lasso(alpha = 0.01, random_state=1)\n",
    "enet = ElasticNet(alpha=0.03, l1_ratio=0.01, random_state=1)\n",
    "d_tree = DecisionTreeRegressor(max_depth=6, min_samples_split=10, min_samples_leaf=15, random_state=1)\n",
    "rf = RandomForestRegressor(n_estimators=100,  max_depth=9, min_samples_split=50,\n",
    "                           min_samples_leaf=5, random_state=1, n_jobs=-1)\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=100, max_depth=9, min_child_weight=5, gamma=0.1, n_jobs=-1 )\n",
    "model_lgb = lgb.LGBMRegressor(n_estimators=100, max_depth=9, min_child_weight=5, n_jobs=-1,num_leaves=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2337116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성없음\n",
    "lrmodel = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "enet = ElasticNet()\n",
    "d_tree = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "model_xgb = xgb.XGBRegressor()\n",
    "model_lgb = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ceec623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse_r2_score(model):\n",
    "    # cv별 프린팅, 평균 저장\n",
    "    model_name, rmse_list, r2_list = rmse_r2_cv(model)\n",
    "    for i, (rmse, r2) in enumerate(zip(rmse_list, r2_list), start=1):\n",
    "         print(f'{i} FOLDS: {model_name} RMSE: {rmse:.4f}, R2: {r2:.4f}')\n",
    "    print(f'\\n{model_name} mean RMSE: {np.mean(rmse_list):.4f}, mean R2: {np.mean(r2_list):.4f}')\n",
    "    print('='*40)\n",
    "    return model_name, np.mean(rmse_list), np.mean(r2_list)\n",
    "\n",
    "def rmse_r2_cv(model):\n",
    "    # cv별로 학습하는 함수\n",
    "    tscv = TimeSeriesSplit(n_splits=10)\n",
    "    rmse_list = []\n",
    "    r2_list = []\n",
    "    model_name = model.__class__.__name__\n",
    "    for _, (train_index, test_index) in tqdm(enumerate(tscv.split(X), start=1), desc=f'{model_name} Cross Validations...', total=10):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        rmse = RMSE(y_test, pred)\n",
    "        r2 = r2_score(y_test, pred)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "    return model_name, rmse_list, r2_list\n",
    "\n",
    "def RMSE(y, y_pred):\n",
    "    rmse = mean_squared_error(y, y_pred) ** 0.5\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f899fc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LinearRegression Cross Validations...: 100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 20.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: LinearRegression RMSE: 10084.0162, R2: 0.6496\n",
      "2 FOLDS: LinearRegression RMSE: 9080.6999, R2: 0.5288\n",
      "3 FOLDS: LinearRegression RMSE: 6591.1190, R2: 0.6617\n",
      "4 FOLDS: LinearRegression RMSE: 5906.4291, R2: 0.5981\n",
      "5 FOLDS: LinearRegression RMSE: 5854.3037, R2: 0.4538\n",
      "6 FOLDS: LinearRegression RMSE: 5383.9206, R2: 0.5477\n",
      "7 FOLDS: LinearRegression RMSE: 5841.3210, R2: 0.5347\n",
      "8 FOLDS: LinearRegression RMSE: 8988.2098, R2: -0.3882\n",
      "9 FOLDS: LinearRegression RMSE: 4756.1851, R2: 0.2545\n",
      "10 FOLDS: LinearRegression RMSE: 4739.9987, R2: 0.0180\n",
      "\n",
      "LinearRegression mean RMSE: 6722.6203, mean R2: 0.3859\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Cross Validations...: 100%|██████████████████████████████████████████████████████| 10/10 [00:00<00:00, 32.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: Ridge RMSE: 10084.0369, R2: 0.6496\n",
      "2 FOLDS: Ridge RMSE: 9080.6665, R2: 0.5288\n",
      "3 FOLDS: Ridge RMSE: 6591.1186, R2: 0.6617\n",
      "4 FOLDS: Ridge RMSE: 5906.4287, R2: 0.5981\n",
      "5 FOLDS: Ridge RMSE: 5854.3037, R2: 0.4538\n",
      "6 FOLDS: Ridge RMSE: 5383.9201, R2: 0.5478\n",
      "7 FOLDS: Ridge RMSE: 5841.3208, R2: 0.5347\n",
      "8 FOLDS: Ridge RMSE: 8988.2091, R2: -0.3882\n",
      "9 FOLDS: Ridge RMSE: 4756.1838, R2: 0.2545\n",
      "10 FOLDS: Ridge RMSE: 4739.9990, R2: 0.0180\n",
      "\n",
      "Ridge mean RMSE: 6722.6187, mean R2: 0.3859\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lasso Cross Validations...: 100%|██████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: Lasso RMSE: 10085.3300, R2: 0.6495\n",
      "2 FOLDS: Lasso RMSE: 9078.1201, R2: 0.5291\n",
      "3 FOLDS: Lasso RMSE: 6590.9537, R2: 0.6618\n",
      "4 FOLDS: Lasso RMSE: 5906.2105, R2: 0.5981\n",
      "5 FOLDS: Lasso RMSE: 5854.5504, R2: 0.4537\n",
      "6 FOLDS: Lasso RMSE: 5383.5709, R2: 0.5478\n",
      "7 FOLDS: Lasso RMSE: 5841.1812, R2: 0.5348\n",
      "8 FOLDS: Lasso RMSE: 8988.0814, R2: -0.3882\n",
      "9 FOLDS: Lasso RMSE: 4754.0045, R2: 0.2551\n",
      "10 FOLDS: Lasso RMSE: 4740.5592, R2: 0.0178\n",
      "\n",
      "Lasso mean RMSE: 6722.2562, mean R2: 0.3859\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ElasticNet Cross Validations...: 100%|█████████████████████████████████████████████████| 10/10 [00:00<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: ElasticNet RMSE: 10187.8392, R2: 0.6423\n",
      "2 FOLDS: ElasticNet RMSE: 8660.3586, R2: 0.5714\n",
      "3 FOLDS: ElasticNet RMSE: 6574.6227, R2: 0.6634\n",
      "4 FOLDS: ElasticNet RMSE: 5887.6433, R2: 0.6007\n",
      "5 FOLDS: ElasticNet RMSE: 5846.1615, R2: 0.4553\n",
      "6 FOLDS: ElasticNet RMSE: 5350.0822, R2: 0.5534\n",
      "7 FOLDS: ElasticNet RMSE: 5822.6967, R2: 0.5377\n",
      "8 FOLDS: ElasticNet RMSE: 8951.1368, R2: -0.3768\n",
      "9 FOLDS: ElasticNet RMSE: 4650.9873, R2: 0.2871\n",
      "10 FOLDS: ElasticNet RMSE: 4763.4061, R2: 0.0083\n",
      "\n",
      "ElasticNet mean RMSE: 6669.4935, mean R2: 0.3943\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor Cross Validations...: 100%|██████████████████████████████████████| 10/10 [00:15<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: DecisionTreeRegressor RMSE: 11924.6381, R2: 0.5100\n",
      "2 FOLDS: DecisionTreeRegressor RMSE: 7105.4291, R2: 0.7115\n",
      "3 FOLDS: DecisionTreeRegressor RMSE: 5878.3866, R2: 0.7309\n",
      "4 FOLDS: DecisionTreeRegressor RMSE: 4808.9984, R2: 0.7336\n",
      "5 FOLDS: DecisionTreeRegressor RMSE: 3732.3016, R2: 0.7780\n",
      "6 FOLDS: DecisionTreeRegressor RMSE: 3359.9140, R2: 0.8239\n",
      "7 FOLDS: DecisionTreeRegressor RMSE: 4628.5654, R2: 0.7079\n",
      "8 FOLDS: DecisionTreeRegressor RMSE: 3816.0528, R2: 0.7498\n",
      "9 FOLDS: DecisionTreeRegressor RMSE: 2632.1530, R2: 0.7717\n",
      "10 FOLDS: DecisionTreeRegressor RMSE: 2414.2321, R2: 0.7452\n",
      "\n",
      "DecisionTreeRegressor mean RMSE: 5030.0671, mean R2: 0.7262\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor Cross Validations...: 100%|█████████████████████████████████████| 10/10 [21:10<00:00, 127.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: RandomForestRegressor RMSE: 7931.6618, R2: 0.7832\n",
      "2 FOLDS: RandomForestRegressor RMSE: 5423.0674, R2: 0.8319\n",
      "3 FOLDS: RandomForestRegressor RMSE: 4887.9955, R2: 0.8140\n",
      "4 FOLDS: RandomForestRegressor RMSE: 3700.0011, R2: 0.8423\n",
      "5 FOLDS: RandomForestRegressor RMSE: 2973.5829, R2: 0.8591\n",
      "6 FOLDS: RandomForestRegressor RMSE: 2593.5523, R2: 0.8951\n",
      "7 FOLDS: RandomForestRegressor RMSE: 3625.7346, R2: 0.8207\n",
      "8 FOLDS: RandomForestRegressor RMSE: 3288.5715, R2: 0.8142\n",
      "9 FOLDS: RandomForestRegressor RMSE: 1956.3370, R2: 0.8739\n",
      "10 FOLDS: RandomForestRegressor RMSE: 1733.7020, R2: 0.8686\n",
      "\n",
      "RandomForestRegressor mean RMSE: 3811.4206, mean R2: 0.8403\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBRegressor Cross Validations...: 100%|███████████████████████████████████████████████| 10/10 [00:36<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: XGBRegressor RMSE: 6539.0258, R2: 0.8527\n",
      "2 FOLDS: XGBRegressor RMSE: 4717.6404, R2: 0.8728\n",
      "3 FOLDS: XGBRegressor RMSE: 4358.4450, R2: 0.8521\n",
      "4 FOLDS: XGBRegressor RMSE: 3444.6749, R2: 0.8633\n",
      "5 FOLDS: XGBRegressor RMSE: 2780.2411, R2: 0.8768\n",
      "6 FOLDS: XGBRegressor RMSE: 2651.7445, R2: 0.8903\n",
      "7 FOLDS: XGBRegressor RMSE: 3251.0589, R2: 0.8559\n",
      "8 FOLDS: XGBRegressor RMSE: 3385.2743, R2: 0.8031\n",
      "9 FOLDS: XGBRegressor RMSE: 1750.6406, R2: 0.8990\n",
      "10 FOLDS: XGBRegressor RMSE: 1635.4810, R2: 0.8831\n",
      "\n",
      "XGBRegressor mean RMSE: 3451.4226, mean R2: 0.8649\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:   0%|                                                       | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 572\n",
      "[LightGBM] [Info] Number of data points in the train set: 38649, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 26236.340293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  10%|████▋                                          | 1/10 [00:00<00:03,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 639\n",
      "[LightGBM] [Info] Number of data points in the train set: 77292, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 26152.606453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  20%|█████████▍                                     | 2/10 [00:00<00:02,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 657\n",
      "[LightGBM] [Info] Number of data points in the train set: 115935, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 24629.378074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  30%|██████████████                                 | 3/10 [00:01<00:02,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 685\n",
      "[LightGBM] [Info] Number of data points in the train set: 154578, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 23566.597899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  40%|██████████████████▊                            | 4/10 [00:01<00:02,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 193221, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 22362.432696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  50%|███████████████████████▌                       | 5/10 [00:02<00:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 231864, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 21205.027689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  60%|████████████████████████████▏                  | 6/10 [00:02<00:02,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 270507, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 20255.548045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  70%|████████████████████████████████▉              | 7/10 [00:03<00:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 309150, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 19362.939107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  80%|█████████████████████████████████████▌         | 8/10 [00:04<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 347793, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 18529.221065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "LGBMRegressor Cross Validations...:  90%|██████████████████████████████████████████▎    | 9/10 [00:05<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 876\n",
      "[LightGBM] [Info] Number of data points in the train set: 386436, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 17601.731094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LGBMRegressor Cross Validations...: 100%|██████████████████████████████████████████████| 10/10 [00:06<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: LGBMRegressor RMSE: 6428.6204, R2: 0.8576\n",
      "2 FOLDS: LGBMRegressor RMSE: 5057.1179, R2: 0.8539\n",
      "3 FOLDS: LGBMRegressor RMSE: 4376.2995, R2: 0.8509\n",
      "4 FOLDS: LGBMRegressor RMSE: 3770.0855, R2: 0.8363\n",
      "5 FOLDS: LGBMRegressor RMSE: 2823.3683, R2: 0.8730\n",
      "6 FOLDS: LGBMRegressor RMSE: 2868.6785, R2: 0.8716\n",
      "7 FOLDS: LGBMRegressor RMSE: 3449.6457, R2: 0.8377\n",
      "8 FOLDS: LGBMRegressor RMSE: 3299.9331, R2: 0.8129\n",
      "9 FOLDS: LGBMRegressor RMSE: 1906.4965, R2: 0.8802\n",
      "10 FOLDS: LGBMRegressor RMSE: 1851.5836, R2: 0.8502\n",
      "\n",
      "LGBMRegressor mean RMSE: 3583.1829, mean R2: 0.8524\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "for model in [lrmodel, ridge, lasso, enet, d_tree, rf, model_xgb, model_lgb]:\n",
    "    model_name, mean_rmse_score, mean_r2_score = print_rmse_r2_score(model)\n",
    "    models.append(model_name)\n",
    "    rmse_scores.append(mean_rmse_score)\n",
    "    r2_scores.append(mean_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a54c571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>6722.620306</td>\n",
       "      <td>0.385872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>6722.618718</td>\n",
       "      <td>0.385872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>6722.256191</td>\n",
       "      <td>0.385947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>6669.493452</td>\n",
       "      <td>0.394279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>5030.067124</td>\n",
       "      <td>0.726242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>3811.420617</td>\n",
       "      <td>0.840293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>3451.422637</td>\n",
       "      <td>0.864900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>3583.182899</td>\n",
       "      <td>0.852412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model         RMSE        R2\n",
       "0       LinearRegression  6722.620306  0.385872\n",
       "1                  Ridge  6722.618718  0.385872\n",
       "2                  Lasso  6722.256191  0.385947\n",
       "3             ElasticNet  6669.493452  0.394279\n",
       "4  DecisionTreeRegressor  5030.067124  0.726242\n",
       "5  RandomForestRegressor  3811.420617  0.840293\n",
       "6           XGBRegressor  3451.422637  0.864900\n",
       "7          LGBMRegressor  3583.182899  0.852412"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'Model': models, 'RMSE': rmse_scores, 'R2': r2_scores}).reset_index(drop=True)\n",
    "result_df\n",
    "# 하이퍼파라미터 튜닝 없는 자료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aba97e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>6722.620306</td>\n",
       "      <td>0.385872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>6722.619036</td>\n",
       "      <td>0.385872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>6722.616620</td>\n",
       "      <td>0.385873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>6715.504320</td>\n",
       "      <td>0.387007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>5866.145420</td>\n",
       "      <td>0.602225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>4549.020550</td>\n",
       "      <td>0.760308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>3298.991401</td>\n",
       "      <td>0.880218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>3700.854867</td>\n",
       "      <td>0.841873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model         RMSE        R2\n",
       "0       LinearRegression  6722.620306  0.385872\n",
       "1                  Ridge  6722.619036  0.385872\n",
       "2                  Lasso  6722.616620  0.385873\n",
       "3             ElasticNet  6715.504320  0.387007\n",
       "4  DecisionTreeRegressor  5866.145420  0.602225\n",
       "5  RandomForestRegressor  4549.020550  0.760308\n",
       "6           XGBRegressor  3298.991401  0.880218\n",
       "7          LGBMRegressor  3700.854867  0.841873"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존dacon 하이퍼파라미터 튜닝 자료 \n",
    "result_df = pd.DataFrame({'Model': models, 'RMSE': rmse_scores, 'R2': r2_scores}).reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19de5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = [[84, 202312,10,10 ,15,3.5,2920010200,0]]\n",
    "X_predict_df= pd.DataFrame(X_predict,columns=['전용면적(㎡)', '계약년월','층', '건축나이','거래건수','기준금리','법정동코드','지하철역수'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da8ed7",
   "metadata": {},
   "source": [
    "X = data[['전용면적(㎡)', '계약년월','층', '건축나이','거래건수','기준금리','법정동코드','지하철역수']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "275fbec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: 36301.60496480996\n",
      "Ridge: 36301.602554979734\n",
      "Lasso: 36297.13036408834\n",
      "ElasticNet: 36014.534532725345\n",
      "DecisionTreeRegressor: 36000.0\n",
      "RandomForestRegressor: 37927.0\n",
      "XGBRegressor: 35704.38671875\n",
      "LGBMRegressor :37773.80578399077\n"
     ]
    }
   ],
   "source": [
    "print(f\"LinearRegression: {lrmodel.predict(X_predict_df)[0]}\")\n",
    "print(f\"Ridge: {ridge.predict(X_predict_df)[0]}\")\n",
    "print(f\"Lasso: {lasso.predict(X_predict_df)[0]}\")\n",
    "print(f\"ElasticNet: {enet.predict(X_predict_df)[0]}\")\n",
    "print(f\"DecisionTreeRegressor: {d_tree.predict(X_predict_df)[0]}\")\n",
    "print(f\"RandomForestRegressor: {rf.predict(X_predict_df)[0]}\")\n",
    "print(f\"XGBRegressor: {model_xgb.predict(X_predict_df)[0]}\")\n",
    "print(f\"LGBMRegressor :{model_lgb.predict(X_predict_df)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ec6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "enet = ElasticNet()\n",
    "d_tree = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "model_xgb = xgb.XGBRegressor()\n",
    "model_lgb = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = LinearRegression(n_jobs=-1)\n",
    "ridge = Ridge(alpha=0.8, random_state=1)\n",
    "lasso = Lasso(alpha = 0.01, random_state=1)\n",
    "enet = ElasticNet(alpha=0.03, l1_ratio=0.01, random_state=1)\n",
    "d_tree = DecisionTreeRegressor(max_depth=6, min_samples_split=10, min_samples_leaf=15, random_state=1)\n",
    "rf = RandomForestRegressor(n_estimators=100,  max_depth=9, min_samples_split=50,\n",
    "                           min_samples_leaf=5, random_state=1, n_jobs=-1)\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=100, max_depth=9, min_child_weight=5, gamma=0.1, n_jobs=-1 )\n",
    "model_lgb = lgb.LGBMRegressor(n_estimators=100, max_depth=9, min_child_weight=5, n_jobs=-1,num_leaves=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eedf6b5",
   "metadata": {},
   "source": [
    "##  하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b78d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c904de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "lr_grid_search = GridSearchCV(estimator=LinearRegression(n_jobs=-1),\n",
    "                              param_grid=lr_params,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              cv=10,\n",
    "                              n_jobs=-1)\n",
    "lr_grid_search.fit(X, y)\n",
    "best_lr_model = lr_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7a7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ridge\n",
    "ridge_params = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "ridge_grid_search = GridSearchCV(estimator=Ridge(random_state=1),\n",
    "                                 param_grid=ridge_params,\n",
    "                                 scoring='neg_mean_squared_error',\n",
    "                                 cv=10,\n",
    "                                 n_jobs=-1)\n",
    "ridge_grid_search.fit(X, y)\n",
    "best_ridge_model = ridge_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f020aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "lasso_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "lasso_grid_search = GridSearchCV(estimator=Lasso(random_state=1),\n",
    "                                 param_grid=lasso_params,\n",
    "                                 scoring='neg_mean_squared_error',\n",
    "                                 cv=10,\n",
    "                                 n_jobs=-1)\n",
    "lasso_grid_search.fit(X, y)\n",
    "best_lasso_model = lasso_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2afdb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet\n",
    "enet_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1.0],\n",
    "    'l1_ratio': [0.01, 0.1, 0.5, 0.9]\n",
    "}\n",
    "enet_grid_search = GridSearchCV(estimator=ElasticNet(random_state=1),\n",
    "                                param_grid=enet_params,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                cv=10,\n",
    "                                n_jobs=-1)\n",
    "enet_grid_search.fit(X, y)\n",
    "best_enet_model = enet_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1604682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "d_tree_params = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "d_tree_grid_search = GridSearchCV(estimator=DecisionTreeRegressor(random_state=1),\n",
    "                                  param_grid=d_tree_params,\n",
    "                                  scoring='neg_mean_squared_error',\n",
    "                                  cv=10,\n",
    "                                  n_jobs=-1)\n",
    "d_tree_grid_search.fit(X, y)\n",
    "best_d_tree_model = d_tree_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0126b6d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1586\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1587\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1590\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1698\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1699\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m rf_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      8\u001b[0m rf_grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mRandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      9\u001b[0m                               param_grid\u001b[38;5;241m=\u001b[39mrf_params,\n\u001b[0;32m     10\u001b[0m                               scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m                               cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     12\u001b[0m                               n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mrf_grid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m best_rf_model \u001b[38;5;241m=\u001b[39m rf_grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1942\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\parallel.py:1640\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m   1639\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1640\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_abort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\parallel.py:1551\u001b[0m, in \u001b[0;36mParallel._abort\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabort_everything\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# If the backend is managed externally we need to make sure\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# to leave it in a working state to allow for future jobs\u001b[39;00m\n\u001b[0;32m   1549\u001b[0m     \u001b[38;5;66;03m# scheduling.\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m     ensure_ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend\n\u001b[1;32m-> 1551\u001b[0m     \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabort_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\_parallel_backends.py:632\u001b[0m, in \u001b[0;36mLokyBackend.abort_everything\u001b[1;34m(self, ensure_ready)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mabort_everything\u001b[39m(\u001b[38;5;28mself\u001b[39m, ensure_ready\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    630\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_ready:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\executor.py:75\u001b[0m, in \u001b[0;36mMemmappingExecutor.terminate\u001b[1;34m(self, kill_workers)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mterminate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kill_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkill_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# on by the resource_tracker.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1303\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[1;34m(self, wait, kill_workers)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_manager_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wait:\n\u001b[0;32m   1300\u001b[0m     \u001b[38;5;66;03m# This locks avoids concurrent join if the interpreter\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m     \u001b[38;5;66;03m# is shutting down.\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _global_shutdown_lock:\n\u001b[1;32m-> 1303\u001b[0m         \u001b[43mexecutor_manager_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1304\u001b[0m         _threads_wakeups\u001b[38;5;241m.\u001b[39mpop(executor_manager_thread, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# already determined that the C code is done\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[1;32m-> 1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1028\u001b[0m     lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "rf_grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=1, n_jobs=-1),\n",
    "                              param_grid=rf_params,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              cv=10,\n",
    "                              n_jobs=-1)\n",
    "rf_grid_search.fit(X, y)\n",
    "best_rf_model = rf_grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fc7771b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|                                                                     | 0/12 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 18\u001b[0m\n\u001b[0;32m     10\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39mtotal_combinations, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrid Search Progress\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m xgb_grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb\u001b[38;5;241m.\u001b[39mXGBRegressor(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     13\u001b[0m                                param_grid\u001b[38;5;241m=\u001b[39mxgb_params,\n\u001b[0;32m     14\u001b[0m                                scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m                                cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     16\u001b[0m                                n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mxgb_grid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m best_xgb_model \u001b[38;5;241m=\u001b[39m xgb_grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1942\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1584\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1586\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1587\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1590\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine\\lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1698\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1699\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [ 10, 15],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0.1, 0.3]\n",
    "}\n",
    "\n",
    "# 진행 상황 표시 준비\n",
    "total_combinations = len(xgb_params['n_estimators']) * len(xgb_params['max_depth']) * len(xgb_params['min_child_weight']) * len(xgb_params['gamma'])\n",
    "progress_bar = tqdm(total=total_combinations, desc=\"Grid Search Progress\")\n",
    "\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb.XGBRegressor(n_jobs=-1),\n",
    "                               param_grid=xgb_params,\n",
    "                               scoring='neg_mean_squared_error',\n",
    "                               cv=10,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "xgb_grid_search.fit(X, y)\n",
    "\n",
    "best_xgb_model = xgb_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ada3aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 915\n",
      "[LightGBM] [Info] Number of data points in the train set: 425079, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 16811.097775\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LightGBM\n",
    "lgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'num_leaves': [10, 20, 30]\n",
    "}\n",
    "lgb_grid_search = GridSearchCV(estimator=lgb.LGBMRegressor(n_jobs=-1),\n",
    "                               param_grid=lgb_params,\n",
    "                               scoring='neg_mean_squared_error',\n",
    "                               cv=10,\n",
    "                               n_jobs=-1)\n",
    "lgb_grid_search.fit(X, y)\n",
    "best_lgb_model = lgb_grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56a845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Linear Regression Model: LinearRegression(n_jobs=-1)\n",
      "Best Ridge Model: Ridge(alpha=2.0, random_state=1)\n",
      "Best Lasso Model: Lasso(alpha=0.001, random_state=1)\n",
      "Best ElasticNet Model: ElasticNet(alpha=0.1, random_state=1)\n",
      "Best Decision Tree Model: DecisionTreeRegressor(max_depth=10, min_samples_split=10, random_state=1)\n",
      "Best LightGBM Model: LGBMRegressor(max_depth=10, min_child_weight=1, n_estimators=200, n_jobs=-1,\n",
      "              num_leaves=30)\n"
     ]
    }
   ],
   "source": [
    "# 출력\n",
    "print(\"Best Linear Regression Model:\", best_lr_model)\n",
    "print(\"Best Ridge Model:\", best_ridge_model)\n",
    "print(\"Best Lasso Model:\", best_lasso_model)\n",
    "print(\"Best ElasticNet Model:\", best_enet_model)\n",
    "print(\"Best Decision Tree Model:\", best_d_tree_model)\n",
    "# print(\"Best RandomForest Model:\", best_rf_model)\n",
    "# print(\"Best XGBoost Model:\", best_xgb_model)\n",
    "print(\"Best LightGBM Model:\", best_lgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1380e7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Model: RandomForestRegressor(max_depth=10, min_samples_split=10, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "best_rf_model=RandomForestRegressor(max_depth=10,min_samples_split=10,n_estimators=50,n_jobs=-1,random_state=1)\n",
    "print(\"Best RandomForest Model:\", best_rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41284207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=200, n_jobs=-1, num_leaves=20, num_parallel_tree=None,\n",
      "             predictor=None, ...)\n"
     ]
    }
   ],
   "source": [
    "best_xgb_model= xgb.XGBRegressor(max_depth=5,min_child_weight=5,n_estimators=200,n_jobs=-1,num_leaves=20)\n",
    "print(\"Best XGBoost Model:\", best_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "164d86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = best_lr_model\n",
    "ridge = best_ridge_model\n",
    "lasso = best_lasso_model\n",
    "enet = best_enet_model\n",
    "d_tree = best_d_tree_model\n",
    "rf = best_rf_model\n",
    "model_xgb = xgb.XGBRegressor()\n",
    "model_lgb = best_lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb6d5a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBRegressor Cross Validations...:   0%|                                                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "XGBRegressor Cross Validations...:  10%|████▊                                           | 1/10 [00:00<00:04,  1.88it/s]\u001b[A\n",
      "XGBRegressor Cross Validations...:  20%|█████████▌                                      | 2/10 [00:01<00:06,  1.26it/s]\u001b[A\n",
      "XGBRegressor Cross Validations...:  30%|██████████████▍                                 | 3/10 [00:02<00:07,  1.05s/it]\u001b[A\n",
      "XGBRegressor Cross Validations...:  40%|███████████████████▏                            | 4/10 [00:04<00:08,  1.36s/it]\u001b[A\n",
      "XGBRegressor Cross Validations...:  50%|████████████████████████                        | 5/10 [00:06<00:08,  1.68s/it]\u001b[A\n",
      "XGBRegressor Cross Validations...:  60%|████████████████████████████▊                   | 6/10 [00:09<00:08,  2.03s/it]\u001b[A\n",
      "XGBRegressor Cross Validations...:  70%|█████████████████████████████████▌              | 7/10 [00:12<00:07,  2.44s/it]\u001b[A\n",
      "XGBRegressor Cross Validations...:  80%|██████████████████████████████████████▍         | 8/10 [00:16<00:05,  2.86s/it]\u001b[A\n",
      "XGBRegressor Cross Validations...:  90%|███████████████████████████████████████████▏    | 9/10 [00:20<00:03,  3.28s/it]\u001b[A\n",
      "XGBRegressor Cross Validations...: 100%|███████████████████████████████████████████████| 10/10 [00:25<00:00,  2.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: XGBRegressor RMSE: 6539.0258, R2: 0.8527\n",
      "2 FOLDS: XGBRegressor RMSE: 4717.6404, R2: 0.8728\n",
      "3 FOLDS: XGBRegressor RMSE: 4358.4450, R2: 0.8521\n",
      "4 FOLDS: XGBRegressor RMSE: 3444.6749, R2: 0.8633\n",
      "5 FOLDS: XGBRegressor RMSE: 2780.2411, R2: 0.8768\n",
      "6 FOLDS: XGBRegressor RMSE: 2651.7445, R2: 0.8903\n",
      "7 FOLDS: XGBRegressor RMSE: 3251.0589, R2: 0.8559\n",
      "8 FOLDS: XGBRegressor RMSE: 3385.2743, R2: 0.8031\n",
      "9 FOLDS: XGBRegressor RMSE: 1750.6406, R2: 0.8990\n",
      "10 FOLDS: XGBRegressor RMSE: 1635.4810, R2: 0.8831\n",
      "\n",
      "XGBRegressor mean RMSE: 3451.4226, mean R2: 0.8649\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model in [model_xgb]:\n",
    "    model_name, mean_rmse_score, mean_r2_score = print_rmse_r2_score(model)\n",
    "    models2.append(model_name)\n",
    "    rmse_scores2.append(mean_rmse_score)\n",
    "    r2_scores2.append(mean_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0e11d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LinearRegression Cross Validations...:   0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "LinearRegression Cross Validations...:  40%|█████████████████▌                          | 4/10 [00:00<00:00, 36.37it/s]\u001b[A\n",
      "LinearRegression Cross Validations...: 100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 18.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: LinearRegression RMSE: 10084.0162, R2: 0.6496\n",
      "2 FOLDS: LinearRegression RMSE: 9080.6999, R2: 0.5288\n",
      "3 FOLDS: LinearRegression RMSE: 6591.1190, R2: 0.6617\n",
      "4 FOLDS: LinearRegression RMSE: 5906.4291, R2: 0.5981\n",
      "5 FOLDS: LinearRegression RMSE: 5854.3037, R2: 0.4538\n",
      "6 FOLDS: LinearRegression RMSE: 5383.9206, R2: 0.5477\n",
      "7 FOLDS: LinearRegression RMSE: 5841.3210, R2: 0.5347\n",
      "8 FOLDS: LinearRegression RMSE: 8988.2098, R2: -0.3882\n",
      "9 FOLDS: LinearRegression RMSE: 4756.1851, R2: 0.2545\n",
      "10 FOLDS: LinearRegression RMSE: 4739.9987, R2: 0.0180\n",
      "\n",
      "LinearRegression mean RMSE: 6722.6203, mean R2: 0.3859\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Cross Validations...:   0%|                                                               | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Ridge Cross Validations...: 100%|██████████████████████████████████████████████████████| 10/10 [00:00<00:00, 31.64it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: Ridge RMSE: 10084.0577, R2: 0.6496\n",
      "2 FOLDS: Ridge RMSE: 9080.6332, R2: 0.5288\n",
      "3 FOLDS: Ridge RMSE: 6591.1182, R2: 0.6617\n",
      "4 FOLDS: Ridge RMSE: 5906.4283, R2: 0.5981\n",
      "5 FOLDS: Ridge RMSE: 5854.3036, R2: 0.4538\n",
      "6 FOLDS: Ridge RMSE: 5383.9196, R2: 0.5478\n",
      "7 FOLDS: Ridge RMSE: 5841.3207, R2: 0.5347\n",
      "8 FOLDS: Ridge RMSE: 8988.2084, R2: -0.3882\n",
      "9 FOLDS: Ridge RMSE: 4756.1824, R2: 0.2545\n",
      "10 FOLDS: Ridge RMSE: 4739.9993, R2: 0.0180\n",
      "\n",
      "Ridge mean RMSE: 6722.6171, mean R2: 0.3859\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Cross Validations...:   0%|                                                               | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Lasso Cross Validations...:  10%|█████▌                                                 | 1/10 [00:00<00:03,  2.71it/s]\u001b[A\n",
      "Lasso Cross Validations...:  30%|████████████████▌                                      | 3/10 [00:00<00:01,  6.50it/s]\u001b[A\n",
      "Lasso Cross Validations...:  50%|███████████████████████████▌                           | 5/10 [00:00<00:00,  9.16it/s]\u001b[A\n",
      "Lasso Cross Validations...:  70%|██████████████████████████████████████▌                | 7/10 [00:00<00:00,  9.32it/s]\u001b[A\n",
      "Lasso Cross Validations...:  90%|█████████████████████████████████████████████████▌     | 9/10 [00:01<00:00,  8.20it/s]\u001b[A\n",
      "Lasso Cross Validations...: 100%|██████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: Lasso RMSE: 10084.0175, R2: 0.6496\n",
      "2 FOLDS: Lasso RMSE: 9080.6973, R2: 0.5288\n",
      "3 FOLDS: Lasso RMSE: 6591.1188, R2: 0.6617\n",
      "4 FOLDS: Lasso RMSE: 5906.4288, R2: 0.5981\n",
      "5 FOLDS: Lasso RMSE: 5854.3040, R2: 0.4538\n",
      "6 FOLDS: Lasso RMSE: 5383.9203, R2: 0.5478\n",
      "7 FOLDS: Lasso RMSE: 5841.3208, R2: 0.5347\n",
      "8 FOLDS: Lasso RMSE: 8988.2097, R2: -0.3882\n",
      "9 FOLDS: Lasso RMSE: 4756.1829, R2: 0.2545\n",
      "10 FOLDS: Lasso RMSE: 4739.9992, R2: 0.0180\n",
      "\n",
      "Lasso mean RMSE: 6722.6199, mean R2: 0.3859\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ElasticNet Cross Validations...:   0%|                                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "ElasticNet Cross Validations...:  10%|█████                                             | 1/10 [00:00<00:02,  4.44it/s]\u001b[A\n",
      "ElasticNet Cross Validations...:  30%|███████████████                                   | 3/10 [00:00<00:00,  9.75it/s]\u001b[A\n",
      "ElasticNet Cross Validations...:  50%|█████████████████████████                         | 5/10 [00:00<00:00, 12.34it/s]\u001b[A\n",
      "ElasticNet Cross Validations...:  70%|███████████████████████████████████               | 7/10 [00:00<00:00, 11.59it/s]\u001b[A\n",
      "ElasticNet Cross Validations...: 100%|█████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.19it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: ElasticNet RMSE: 10115.9765, R2: 0.6474\n",
      "2 FOLDS: ElasticNet RMSE: 8973.1804, R2: 0.5399\n",
      "3 FOLDS: ElasticNet RMSE: 6589.1044, R2: 0.6619\n",
      "4 FOLDS: ElasticNet RMSE: 5903.7623, R2: 0.5985\n",
      "5 FOLDS: ElasticNet RMSE: 5853.8590, R2: 0.4539\n",
      "6 FOLDS: ElasticNet RMSE: 5378.3765, R2: 0.5487\n",
      "7 FOLDS: ElasticNet RMSE: 5839.1982, R2: 0.5351\n",
      "8 FOLDS: ElasticNet RMSE: 8979.0800, R2: -0.3854\n",
      "9 FOLDS: ElasticNet RMSE: 4735.5227, R2: 0.2609\n",
      "10 FOLDS: ElasticNet RMSE: 4745.0650, R2: 0.0159\n",
      "\n",
      "ElasticNet mean RMSE: 6711.3125, mean R2: 0.3877\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeRegressor Cross Validations...:   0%|                                               | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...:  20%|███████▊                               | 2/10 [00:00<00:01,  7.91it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...:  30%|███████████▋                           | 3/10 [00:00<00:01,  5.91it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...:  40%|███████████████▌                       | 4/10 [00:00<00:01,  4.42it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...:  50%|███████████████████▌                   | 5/10 [00:01<00:01,  3.55it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...:  60%|███████████████████████▍               | 6/10 [00:01<00:01,  2.92it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...:  70%|███████████████████████████▎           | 7/10 [00:02<00:01,  2.46it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...:  80%|███████████████████████████████▏       | 8/10 [00:02<00:00,  2.17it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...:  90%|███████████████████████████████████    | 9/10 [00:03<00:00,  1.88it/s]\u001b[A\n",
      "DecisionTreeRegressor Cross Validations...: 100%|██████████████████████████████████████| 10/10 [00:04<00:00,  2.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: DecisionTreeRegressor RMSE: 9403.1285, R2: 0.6953\n",
      "2 FOLDS: DecisionTreeRegressor RMSE: 7404.4691, R2: 0.6867\n",
      "3 FOLDS: DecisionTreeRegressor RMSE: 5821.9738, R2: 0.7361\n",
      "4 FOLDS: DecisionTreeRegressor RMSE: 5223.5020, R2: 0.6857\n",
      "5 FOLDS: DecisionTreeRegressor RMSE: 4610.3214, R2: 0.6613\n",
      "6 FOLDS: DecisionTreeRegressor RMSE: 3262.7735, R2: 0.8339\n",
      "7 FOLDS: DecisionTreeRegressor RMSE: 4068.2798, R2: 0.7743\n",
      "8 FOLDS: DecisionTreeRegressor RMSE: 3926.8799, R2: 0.7350\n",
      "9 FOLDS: DecisionTreeRegressor RMSE: 2618.1870, R2: 0.7741\n",
      "10 FOLDS: DecisionTreeRegressor RMSE: 2316.1177, R2: 0.7655\n",
      "\n",
      "DecisionTreeRegressor mean RMSE: 4865.5633, mean R2: 0.7348\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForestRegressor Cross Validations...:   0%|                                               | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  10%|███▉                                   | 1/10 [00:00<00:05,  1.52it/s]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  20%|███████▊                               | 2/10 [00:01<00:06,  1.18it/s]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  30%|███████████▋                           | 3/10 [00:03<00:07,  1.13s/it]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  40%|███████████████▌                       | 4/10 [00:05<00:08,  1.48s/it]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  50%|███████████████████▌                   | 5/10 [00:07<00:09,  1.88s/it]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  60%|███████████████████████▍               | 6/10 [00:10<00:09,  2.31s/it]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  70%|███████████████████████████▎           | 7/10 [00:14<00:08,  2.87s/it]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  80%|███████████████████████████████▏       | 8/10 [00:19<00:06,  3.41s/it]\u001b[A\n",
      "RandomForestRegressor Cross Validations...:  90%|███████████████████████████████████    | 9/10 [00:24<00:03,  3.92s/it]\u001b[A\n",
      "RandomForestRegressor Cross Validations...: 100%|██████████████████████████████████████| 10/10 [00:30<00:00,  3.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: RandomForestRegressor RMSE: 7982.9836, R2: 0.7804\n",
      "2 FOLDS: RandomForestRegressor RMSE: 6134.4251, R2: 0.7850\n",
      "3 FOLDS: RandomForestRegressor RMSE: 5747.7825, R2: 0.7428\n",
      "4 FOLDS: RandomForestRegressor RMSE: 4557.7212, R2: 0.7607\n",
      "5 FOLDS: RandomForestRegressor RMSE: 4081.8483, R2: 0.7345\n",
      "6 FOLDS: RandomForestRegressor RMSE: 3214.2208, R2: 0.8388\n",
      "7 FOLDS: RandomForestRegressor RMSE: 3994.1889, R2: 0.7825\n",
      "8 FOLDS: RandomForestRegressor RMSE: 3667.2973, R2: 0.7689\n",
      "9 FOLDS: RandomForestRegressor RMSE: 2375.7881, R2: 0.8140\n",
      "10 FOLDS: RandomForestRegressor RMSE: 2213.5201, R2: 0.7858\n",
      "\n",
      "RandomForestRegressor mean RMSE: 4396.9776, mean R2: 0.7793\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:   0%|                                                       | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 572\n",
      "[LightGBM] [Info] Number of data points in the train set: 38649, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 26236.340293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  10%|████▋                                          | 1/10 [00:00<00:02,  3.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 639\n",
      "[LightGBM] [Info] Number of data points in the train set: 77292, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 26152.606453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  20%|█████████▍                                     | 2/10 [00:00<00:03,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 657\n",
      "[LightGBM] [Info] Number of data points in the train set: 115935, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 24629.378074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  30%|██████████████                                 | 3/10 [00:01<00:03,  2.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 685\n",
      "[LightGBM] [Info] Number of data points in the train set: 154578, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 23566.597899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  40%|██████████████████▊                            | 4/10 [00:02<00:03,  1.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 193221, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 22362.432696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  50%|███████████████████████▌                       | 5/10 [00:02<00:03,  1.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 231864, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 21205.027689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  60%|████████████████████████████▏                  | 6/10 [00:03<00:02,  1.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 270507, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 20255.548045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  70%|████████████████████████████████▉              | 7/10 [00:04<00:02,  1.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 309150, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 19362.939107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  80%|█████████████████████████████████████▌         | 8/10 [00:05<00:01,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 347793, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 18529.221065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...:  90%|██████████████████████████████████████████▎    | 9/10 [00:07<00:01,  1.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 876\n",
      "[LightGBM] [Info] Number of data points in the train set: 386436, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 17601.731094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBMRegressor Cross Validations...: 100%|██████████████████████████████████████████████| 10/10 [00:08<00:00,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLDS: LGBMRegressor RMSE: 6296.1548, R2: 0.8634\n",
      "2 FOLDS: LGBMRegressor RMSE: 4880.4806, R2: 0.8639\n",
      "3 FOLDS: LGBMRegressor RMSE: 4114.8149, R2: 0.8682\n",
      "4 FOLDS: LGBMRegressor RMSE: 3449.3652, R2: 0.8629\n",
      "5 FOLDS: LGBMRegressor RMSE: 2442.7352, R2: 0.9049\n",
      "6 FOLDS: LGBMRegressor RMSE: 2626.7739, R2: 0.8923\n",
      "7 FOLDS: LGBMRegressor RMSE: 3250.0985, R2: 0.8560\n",
      "8 FOLDS: LGBMRegressor RMSE: 3139.6736, R2: 0.8306\n",
      "9 FOLDS: LGBMRegressor RMSE: 1753.1504, R2: 0.8987\n",
      "10 FOLDS: LGBMRegressor RMSE: 1668.3073, R2: 0.8784\n",
      "\n",
      "LGBMRegressor mean RMSE: 3362.1554, mean R2: 0.8719\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models2 = []\n",
    "rmse_scores2 = []\n",
    "r2_scores2 = []\n",
    "for model in [lrmodel, ridge, lasso, enet, d_tree, rf, model_lgb]:\n",
    "    model_name, mean_rmse_score, mean_r2_score = print_rmse_r2_score(model)\n",
    "    models2.append(model_name)\n",
    "    rmse_scores2.append(mean_rmse_score)\n",
    "    r2_scores2.append(mean_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a24ef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>6722.620306</td>\n",
       "      <td>0.385872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>6722.617130</td>\n",
       "      <td>0.385872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>6722.619938</td>\n",
       "      <td>0.385872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>6711.312508</td>\n",
       "      <td>0.387669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>4865.563269</td>\n",
       "      <td>0.734787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>4396.977604</td>\n",
       "      <td>0.779326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>3362.155445</td>\n",
       "      <td>0.871926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>3451.422637</td>\n",
       "      <td>0.864900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model         RMSE        R2\n",
       "0       LinearRegression  6722.620306  0.385872\n",
       "1                  Ridge  6722.617130  0.385872\n",
       "2                  Lasso  6722.619938  0.385872\n",
       "3             ElasticNet  6711.312508  0.387669\n",
       "4  DecisionTreeRegressor  4865.563269  0.734787\n",
       "5  RandomForestRegressor  4396.977604  0.779326\n",
       "6          LGBMRegressor  3362.155445  0.871926\n",
       "7           XGBRegressor  3451.422637  0.864900"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[]\n",
    "result_df = pd.DataFrame({'Model': models2, 'RMSE': rmse_scores2, 'R2': r2_scores2}).reset_index(drop=True)\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
